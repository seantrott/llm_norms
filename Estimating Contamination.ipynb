{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ad21f9",
   "metadata": {},
   "source": [
    "# Estimating Data Contamination\n",
    "\n",
    "In this code, I use the approaches outlined [in this paper](https://arxiv.org/pdf/2308.08493.pdf) to ask whether there is evidence of data contamination for any of the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c8cfb",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a3b794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import backoff  # for exponential backoff\n",
    "import os\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # makes figs nicer!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419ac20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_auth():\n",
    "    \"\"\"Try to authenticate with OpenAI.\"\"\"\n",
    "    ## Read in key\n",
    "    with open('src/models/gpt_key', 'r') as f:\n",
    "        lines = f.read().split(\"\\n\")\n",
    "    org = lines[0]\n",
    "    api_key = lines[1]\n",
    "    openai.organization = org # org\n",
    "    openai.api_key = api_key # api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd43f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "### Helper functions\n",
    "def get_number(ans):\n",
    "    \"\"\"Retrieves number from GPT-4 response.\"\"\"\n",
    "    if type(ans) is float:\n",
    "        return ans\n",
    "    res = [float(i) for i in ans.split() if is_number(i)]\n",
    "    if len(res) == 0:\n",
    "        return None\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d521e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_auth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a015d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
    "def pred_tokens(prompt, n=40, model=\"gpt-4\"):\n",
    "    \"\"\"Get response.\"\"\"\n",
    "    output = openai.ChatCompletion.create(\n",
    "        model = model,\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant. Your job is to provide data from published datasets.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "      max_tokens=n,\n",
    "      top_p=1\n",
    "        )\n",
    "\n",
    "    return output# output['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f8340",
   "metadata": {},
   "source": [
    "## Method: reconstructing the `.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40389ae7",
   "metadata": {},
   "source": [
    "### Glasgow Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c5935b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are psycholinguistic norms from the Glasgow Norms dataset. Please continue each row with the correct number from the dataset..\n",
      "word,Length,Arousal.M\n",
      "{word},{length},\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"These are psycholinguistic norms from the Glasgow Norms dataset. Please continue each row with the correct number from the dataset..\" + \\\n",
    "\"\\nword,Length,Arousal.M\" + \\\n",
    "\"\\n{word},{length},\"\n",
    "print(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8f1cec43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Length</th>\n",
       "      <th>Arousal.M</th>\n",
       "      <th>Arousal.SD</th>\n",
       "      <th>Arousal.N</th>\n",
       "      <th>Valence.M</th>\n",
       "      <th>Valence.SD</th>\n",
       "      <th>Valence.N</th>\n",
       "      <th>Dominance.M</th>\n",
       "      <th>Dominance.SD</th>\n",
       "      <th>...</th>\n",
       "      <th>Familiarity.N</th>\n",
       "      <th>AoA.M</th>\n",
       "      <th>AoA.SD</th>\n",
       "      <th>AoA.N</th>\n",
       "      <th>Size.M</th>\n",
       "      <th>Size.SD</th>\n",
       "      <th>Size.N</th>\n",
       "      <th>Gender.M</th>\n",
       "      <th>Gender.SD</th>\n",
       "      <th>Gender.N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>address (postal)</td>\n",
       "      <td>7</td>\n",
       "      <td>3.546</td>\n",
       "      <td>1.940</td>\n",
       "      <td>33</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.739</td>\n",
       "      <td>33</td>\n",
       "      <td>5.114</td>\n",
       "      <td>1.489</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>3.059</td>\n",
       "      <td>1.056</td>\n",
       "      <td>34</td>\n",
       "      <td>3.471</td>\n",
       "      <td>1.419</td>\n",
       "      <td>34</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.612</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>address (speak to)</td>\n",
       "      <td>7</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2.029</td>\n",
       "      <td>34</td>\n",
       "      <td>5.559</td>\n",
       "      <td>1.063</td>\n",
       "      <td>34</td>\n",
       "      <td>6.182</td>\n",
       "      <td>2.066</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>4.800</td>\n",
       "      <td>1.090</td>\n",
       "      <td>35</td>\n",
       "      <td>4.171</td>\n",
       "      <td>1.502</td>\n",
       "      <td>35</td>\n",
       "      <td>3.824</td>\n",
       "      <td>0.954</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aim (objective)</td>\n",
       "      <td>3</td>\n",
       "      <td>4.909</td>\n",
       "      <td>2.340</td>\n",
       "      <td>33</td>\n",
       "      <td>6.382</td>\n",
       "      <td>1.189</td>\n",
       "      <td>34</td>\n",
       "      <td>5.909</td>\n",
       "      <td>2.021</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>4.529</td>\n",
       "      <td>1.334</td>\n",
       "      <td>34</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.399</td>\n",
       "      <td>34</td>\n",
       "      <td>4.235</td>\n",
       "      <td>1.086</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aim (target)</td>\n",
       "      <td>3</td>\n",
       "      <td>5.200</td>\n",
       "      <td>2.214</td>\n",
       "      <td>35</td>\n",
       "      <td>5.600</td>\n",
       "      <td>1.642</td>\n",
       "      <td>35</td>\n",
       "      <td>6.714</td>\n",
       "      <td>1.631</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>3.618</td>\n",
       "      <td>1.534</td>\n",
       "      <td>34</td>\n",
       "      <td>3.686</td>\n",
       "      <td>1.617</td>\n",
       "      <td>35</td>\n",
       "      <td>4.743</td>\n",
       "      <td>1.104</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apple (brand)</td>\n",
       "      <td>5</td>\n",
       "      <td>4.849</td>\n",
       "      <td>2.687</td>\n",
       "      <td>33</td>\n",
       "      <td>5.971</td>\n",
       "      <td>1.902</td>\n",
       "      <td>34</td>\n",
       "      <td>4.600</td>\n",
       "      <td>2.440</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1.553</td>\n",
       "      <td>34</td>\n",
       "      <td>5.353</td>\n",
       "      <td>1.954</td>\n",
       "      <td>34</td>\n",
       "      <td>4.647</td>\n",
       "      <td>1.210</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  Length  Arousal.M  Arousal.SD  Arousal.N  Valence.M  \\\n",
       "0    address (postal)       7      3.546       1.940         33      5.000   \n",
       "1  address (speak to)       7      4.000       2.029         34      5.559   \n",
       "2     aim (objective)       3      4.909       2.340         33      6.382   \n",
       "3        aim (target)       3      5.200       2.214         35      5.600   \n",
       "4       Apple (brand)       5      4.849       2.687         33      5.971   \n",
       "\n",
       "   Valence.SD  Valence.N  Dominance.M  Dominance.SD  ...  Familiarity.N  \\\n",
       "0       0.739         33        5.114         1.489  ...             32   \n",
       "1       1.063         34        6.182         2.066  ...             35   \n",
       "2       1.189         34        5.909         2.021  ...             33   \n",
       "3       1.642         35        6.714         1.631  ...             33   \n",
       "4       1.902         34        4.600         2.440  ...             34   \n",
       "\n",
       "   AoA.M  AoA.SD  AoA.N  Size.M  Size.SD  Size.N  Gender.M  Gender.SD  \\\n",
       "0  3.059   1.056     34   3.471    1.419      34     4.000      0.612   \n",
       "1  4.800   1.090     35   4.171    1.502      35     3.824      0.954   \n",
       "2  4.529   1.334     34   4.500    1.399      34     4.235      1.086   \n",
       "3  3.618   1.534     34   3.686    1.617      35     4.743      1.104   \n",
       "4  6.000   1.553     34   5.353    1.954      34     4.647      1.210   \n",
       "\n",
       "   Gender.N  \n",
       "0        32  \n",
       "1        34  \n",
       "2        34  \n",
       "3        35  \n",
       "4        34  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/raw/glasgow/glasgow.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7179e96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    \n",
    "    word = row['word']\n",
    "    length = row['Length']\n",
    "    arousal = row['Arousal.M']\n",
    "    \n",
    "    p = PROMPT.format(word=word, length = length)\n",
    "    \n",
    "    response = pred_tokens(p, n = 3, model = \"gpt-4\")\n",
    "    extracted_response = response['choices'][0]['message']['content']\n",
    "    \n",
    "    results.append(extracted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b21912ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response'] = results\n",
    "df['num_response'] = df['response'].apply(lambda x: get_number(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cf4f2b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "859"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset = [\"num_response\"])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26dd50",
   "metadata": {},
   "source": [
    "### Assessment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cc1f13c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.5287051752221139, pvalue=5.00548497010235e-63)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.spearmanr(df['num_response'], df['Arousal.M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5fb6c4",
   "metadata": {},
   "source": [
    "### Assessment 2: ROUGE-L\n",
    "\n",
    "Calculate ROUGE-L and compare to those produced under general instruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1de00e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "47856b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge_l(row, target):\n",
    "    \"\"\"\n",
    "    Calculate ROUGE-L score given a hypothesis and reference string.\n",
    "    \"\"\"\n",
    "    hypothesis = str(row[target])\n",
    "    reference = str(row['Arousal.M'])\n",
    "    \n",
    "    rouge = Rouge(metrics=['rouge-l'])\n",
    "    scores = rouge.get_scores(hypothesis, reference)\n",
    "\n",
    "    # Extract ROUGE-L scores\n",
    "    rouge_l = scores[0]['rouge-l']\n",
    "\n",
    "    return rouge_l['f']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9c31e",
   "metadata": {},
   "source": [
    "#### Guided instruction ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e2c4d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rouge_l_guided'] = df.apply(calculate_rouge_l, target = \"response\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1613ab8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18781528722868898"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rouge_l_guided'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "630c7d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24401464770964837"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rouge_l_guided'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac18b431",
   "metadata": {},
   "source": [
    "#### Original norms ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d5665257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glasgow = pd.read_csv(\"data/processed/glasgow/glasgow_gpt-4.csv\")\n",
    "df_merged = pd.merge(df_glasgow, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "003bade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['rouge_l_original'] = df_merged.apply(calculate_rouge_l, target = \"Arousal\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ffe0b291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22894838734251616"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['rouge_l_original'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f19840bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2552888732278159"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['rouge_l_original'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdff95c",
   "metadata": {},
   "source": [
    "#### t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "62a55ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 0.0006557343300089885\n",
      "t: 3.4137185257709834\n",
      "df: 1716\n"
     ]
    }
   ],
   "source": [
    "result = ss.ttest_ind( df_merged['rouge_l_original'], df_merged['rouge_l_guided'])\n",
    "df = (len(df_merged) + len(df_merged)) - 2 \n",
    "print(\"p: {p}\".format(p = result.pvalue))\n",
    "print(\"t: {t}\".format(t = result.statistic))\n",
    "print(\"df: {df}\".format(df = df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95688a1f",
   "metadata": {},
   "source": [
    "### Save contamination test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ab559c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_select = df_merged[['word', 'Length', 'Arousal.M', 'Arousal', 'num_response']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fc90e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_select.to_csv(\"data/processed/glasgow/gpt4_data_contamination_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b149bf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
